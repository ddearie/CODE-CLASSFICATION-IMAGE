{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import the required libraries"
      ],
      "metadata": {
        "id": "70fe-94R3ECL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from itertools import cycle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import classification_report\n",
        "from __future__ import print_function, division\n",
        "\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.ion()\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import datasets, models, transforms\n"
      ],
      "metadata": {
        "id": "8L143ALb2x7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connected to gg colab"
      ],
      "metadata": {
        "id": "wb24Jzde3b67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Op2tj1lb3C4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#evaluation function code"
      ],
      "metadata": {
        "id": "8KpKRy7T35z8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euebw10a-7r4"
      },
      "outputs": [],
      "source": [
        "class get_metric():\n",
        "\n",
        "    def get_accuracy_graph(epochs, train_acc, val_acc):\n",
        "        plt.plot(epochs, train_acc, color='#006BA4')\n",
        "        plt.plot(epochs, val_acc, color='#FF800E')\n",
        "        plt.grid(b=True, which='major', color='lightgray')\n",
        "        plt.grid(b=True, which='minor', color='lightgray')\n",
        "        plt.xticks(np.arange(0, 45, 5))\n",
        "        plt.yticks(np.arange(0.5, 1, 0.05))\n",
        "        plt.rcParams['figure.figsize'] = (8, 6)\n",
        "        plt.rcParams['figure.dpi'] = 600\n",
        "        plt.xlabel(\"Number of Epochs\")\n",
        "        plt.ylabel(\"Accuracy\")\n",
        "        plt.title(\"Training Accuracy vs Validation Accuracy\")\n",
        "        plt.legend(['Training Acc.', 'Validation Acc.'], loc='lower right')\n",
        "        plt.show()\n",
        "\n",
        "    def get_loss_graph(epochs, train_losses, val_losses):  # draw validation and train loss graphs\n",
        "        matplotlib.rcdefaults()\n",
        "        plt.plot(epochs, train_losses, color='#006BA4')\n",
        "        plt.plot(epochs, val_losses, color='#FF800E')\n",
        "        plt.grid(b=True, which='major', color='lightgray')\n",
        "        plt.grid(b=True, which='minor', color='lightgray')\n",
        "        plt.xticks(np.arange(0, 45, 5))\n",
        "        plt.yticks(np.arange(0, 1.2, 0.2))\n",
        "        plt.rcParams['figure.dpi'] = 600\n",
        "        plt.xlabel(\"Number of Epochs\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(\"Training Loss vs Validation Loss\")\n",
        "        plt.legend(['Training Loss', 'Validation Loss'], loc='lower right')\n",
        "        plt.show()\n",
        "\n",
        "    def test_label_predictions(model, device, test_loader):  # calculate outputs on test dataset for get metrics\n",
        "        model.eval()\n",
        "        actuals = []\n",
        "        predictions = []\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = model(data)\n",
        "                prediction = output.argmax(dim=1, keepdim=True)\n",
        "                actuals.extend(target.view_as(prediction))\n",
        "                predictions.extend(prediction)\n",
        "        return [i.item() for i in actuals], [i.item() for i in predictions]\n",
        "\n",
        "    def test_label_predictions_el2(model_0,model_1,model_2,model_3, device, test_loader):\n",
        "\n",
        "        actuals = []\n",
        "        predictions = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "\n",
        "                outputs_0 = model_0(data)\n",
        "                _, predicted_0 =torch.max(outputs_0.data, 1)\n",
        "\n",
        "                outputs_1 = model_1(data)\n",
        "                _, predicted_1 =torch.max(outputs_1.data, 1)\n",
        "\n",
        "                outputs_2 = model_2(data)\n",
        "                _, predicted_2 =torch.max(outputs_2.data, 1)\n",
        "\n",
        "                outputs_3 = model_3(data)\n",
        "                _, predicted_3 =torch.max(outputs_3.data, 1)\n",
        "\n",
        "                final_pred=predicted_1\n",
        "                size=final_pred.size()\n",
        "\n",
        "                for i in range(0,(size[0])):\n",
        "                    a=0\n",
        "                    if predicted_2[i].item()==0 and predicted_3[i].item()==0:\n",
        "\n",
        "                        if predicted_1[i].item()==1:\n",
        "                            final_pred[i]=1\n",
        "\n",
        "                        if predicted_1[i].item()==0:\n",
        "                            final_pred[i]=0\n",
        "                        a+=1\n",
        "\n",
        "                    if (predicted_0[i].item()==1 and predicted_1[i].item()==1) :\n",
        "\n",
        "                        a+=1\n",
        "                        if predicted_3[i].item()==0:\n",
        "                            final_pred[i]=0\n",
        "\n",
        "                        if predicted_3[i].item()!=0:\n",
        "                            final_pred[i]=1\n",
        "                    if a==0:\n",
        "                        final_pred[i]=predicted_2[i]\n",
        "                actuals.extend(target.view_as(final_pred))\n",
        "                predictions.extend(final_pred)\n",
        "        return [i.item() for i in actuals], [i.item() for i in predictions]\n",
        "\n",
        "    def test_model(model ,device, test_loader):\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data in test_loader:\n",
        "                images, labels = data[0].to(device), data[1].to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        print('Correct Prediction: {:d}  Total Images: {:d}'.format(correct, total))\n",
        "        print('Test Accuracy = {:f}'.format(correct / total))\n",
        "\n",
        "    def test_model_el2(model_0,model_1,model_2,model_3,device, test_loader):\n",
        "\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data in test_loader:\n",
        "\n",
        "                images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "                outputs_0 = model_0(images)\n",
        "                _, predicted_0 =torch.max(outputs_0.data, 1)\n",
        "\n",
        "                outputs_1 = model_1(images)\n",
        "                _, predicted_1 =torch.max(outputs_1.data, 1)\n",
        "\n",
        "                outputs_2 = model_2(images)\n",
        "                _, predicted_2 =torch.max(outputs_2.data, 1)\n",
        "\n",
        "                outputs_3 = model_3(images)\n",
        "                _, predicted_3 =torch.max(outputs_3.data, 1)\n",
        "\n",
        "                final_pred=predicted_1\n",
        "                size=final_pred.size()\n",
        "\n",
        "                for i in range(0,(size[0])):\n",
        "                    a=0\n",
        "                    if predicted_2[i].item()==0 and predicted_3[i].item()==0:\n",
        "\n",
        "                        if predicted_1[i].item()==1:\n",
        "                            final_pred[i]=1\n",
        "\n",
        "                        if predicted_1[i].item()==0:\n",
        "                            final_pred[i]=0\n",
        "                        a+=1\n",
        "\n",
        "                    if (predicted_0[i].item()==1 and predicted_1[i].item()==1):\n",
        "\n",
        "                        a+=1\n",
        "\n",
        "                        if predicted_3[i].item()==0:\n",
        "                            final_pred[i]=0\n",
        "                        if predicted_3[i].item()!=0:\n",
        "                            final_pred[i]=1\n",
        "                    if a==0:\n",
        "                        final_pred[i]=predicted_2[i]\n",
        "\n",
        "                total += labels.size(0)\n",
        "                correct += (final_pred == labels).sum().item()\n",
        "        print('Correct Prediction: {:d}  Total Images: {:d}'.format(correct, total))\n",
        "        print('Test Accuracy = {:f}'.format(correct / total))\n",
        "\n",
        "    def get_classification_report(truth, predict):  # create classification report for each class with scikit-learn library\n",
        "        print('Classification Report :\\n', classification_report(truth, predict))\n",
        "\n",
        "    def get_confusion_matrix(actuals, predictions):  # create confusion matrix for each class with scikit-learn library\n",
        "        matplotlib.rcdefaults()\n",
        "        print('Confusion matrix:\\n',confusion_matrix(actuals, predictions))\n",
        "        cf_matrix=confusion_matrix(actuals, predictions)\n",
        "        sns.heatmap(cf_matrix, annot=True,fmt='g', cmap='Blues')\n",
        "\n",
        "    def get_cohen_kappa(actuals, predictions):  # get cohen kapa score for   determine model performance\n",
        "        cps = cohen_kappa_score(actuals, predictions)\n",
        "        print('Kappa Score of this model:\\n', cps)\n",
        "\n",
        "    def test_class_probabilities(model, device, test_loader, which_class):\n",
        "\n",
        "        truths = []\n",
        "        probabilities = []\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = model(data).cuda().cpu()\n",
        "                prediction = output.argmax(dim=1, keepdim=True)\n",
        "                truths.extend(target.view_as(prediction) == which_class)\n",
        "                probabilities.extend(np.exp(output[:, which_class]))\n",
        "        return [i.item() for i in truths], [i.item() for i in probabilities]\n",
        "    def test_class_probabilities_el2(model_0,model_1,model_2,model_3, device, test_loader, which_class):\n",
        "\n",
        "        truths = []\n",
        "        probabilities = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "\n",
        "                data, target = data.to(device), target.to(device)\n",
        "\n",
        "                outputs_0 = model_0(data)\n",
        "                _, predicted_0 =torch.max(outputs_0.data, 1)\n",
        "\n",
        "                outputs_1 = model_1(data)\n",
        "                _, predicted_1 =torch.max(outputs_1.data, 1)\n",
        "\n",
        "                outputs_2 = model_2(data)\n",
        "                _, predicted_2 =torch.max(outputs_2.data, 1)\n",
        "\n",
        "                outputs_3 = model_3(data)\n",
        "                _, predicted_3 =torch.max(outputs_3.data, 1)\n",
        "\n",
        "                final_pred=predicted_1\n",
        "                out=outputs_1\n",
        "                size=final_pred.size()\n",
        "\n",
        "                for i in range(0,(size[0])):\n",
        "                    a=0\n",
        "                    if predicted_2[i].item()==0 and predicted_3[i].item()==0:\n",
        "\n",
        "                        if predicted_1[i].item()==1:\n",
        "                            #final_pred[i]=1\n",
        "                            out[i]=outputs_1[i]\n",
        "\n",
        "                        if predicted_1[i].item()==0:\n",
        "                            final_pred[i]=0\n",
        "                            out[i]=outputs_1[i]\n",
        "                        a+=1\n",
        "\n",
        "                    if (predicted_0[i].item()==1 and predicted_1[i].item()==1):\n",
        "\n",
        "                        a+=1\n",
        "\n",
        "                        if predicted_3[i].item()==0:\n",
        "                            #final_pred[i]=0\n",
        "                            out[i]=outputs_3[i]\n",
        "\n",
        "                        if predicted_3[i].item()!=0:\n",
        "                            #final_pred[i]=1\n",
        "                            out[i]=outputs_3[i]\n",
        "                    if a==0:\n",
        "                        #final_pred[i]=predicted_2[i]\n",
        "                        out[i]=outputs_2[i]\n",
        "                prediction = out.argmax(dim=1, keepdim=True)\n",
        "                truths.extend(target.view_as(prediction) == which_class)\n",
        "                probabilities.extend(np.exp(out.cuda().cpu()[:, which_class]))\n",
        "        return [i.item() for i in truths], [i.item() for i in probabilities]\n",
        "\n",
        "    def get_roc_curves_el2(model_0,model_1,model_2,model_3, device, data):  # draw Roc curves and calculate auc score for each class\n",
        "        fpr = dict()\n",
        "        tpr = dict()\n",
        "        roc_auc = dict()\n",
        "\n",
        "        actuals, class_probabilities = get_metric.test_class_probabilities_el2(model_0,model_1,model_2,model_3, device, data, 0)\n",
        "        fpr[0], tpr[0], _ = roc_curve(actuals, class_probabilities)\n",
        "        roc_auc[0] = roc_auc_score(actuals, class_probabilities)\n",
        "\n",
        "        actuals, class_probabilities = get_metric.test_class_probabilities_el2(model_0,model_1,model_2,model_3, device, data, 1)\n",
        "        fpr[1], tpr[1], _ = roc_curve(actuals, class_probabilities)\n",
        "        roc_auc[1] = roc_auc_score(actuals, class_probabilities)\n",
        "\n",
        "        print(\"Auc Score For Each Class: \", roc_auc)\n",
        "\n",
        "        matplotlib.rcdefaults()\n",
        "        plt.figure()\n",
        "        colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "        for i, color in zip(range(2), colors):\n",
        "            plt.plot(fpr[i], tpr[i], color=color, lw=1,\n",
        "                     label='ROC curve of class {0} (area = {1:0.4f})'\n",
        "                           ''.format(i, roc_auc[i]))\n",
        "        plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n",
        "\n",
        "    def get_roc_curves(model, device, data):  # draw Roc curves and calculate auc score for each class\n",
        "        fpr = dict()\n",
        "        tpr = dict()\n",
        "        roc_auc = dict()\n",
        "\n",
        "        actuals, class_probabilities = get_metric.test_class_probabilities(model, device, data, 0)\n",
        "        fpr[0], tpr[0], _ = roc_curve(actuals, class_probabilities)\n",
        "        roc_auc[0] = roc_auc_score(actuals, class_probabilities)\n",
        "\n",
        "        actuals, class_probabilities = get_metric.test_class_probabilities(model, device, data, 1)\n",
        "        fpr[1], tpr[1], _ = roc_curve(actuals, class_probabilities)\n",
        "        roc_auc[1] = roc_auc_score(actuals, class_probabilities)\n",
        "\n",
        "        print(\"Auc Score For Each Class: \", roc_auc)\n",
        "\n",
        "        matplotlib.rcdefaults()\n",
        "        plt.figure()\n",
        "        colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "        for i, color in zip(range(2), colors):\n",
        "            plt.plot(fpr[i], tpr[i], color=color, lw=1,\n",
        "                     label='ROC curve of class {0} (area = {1:0.4f})'\n",
        "                           ''.format(i, roc_auc[i]))\n",
        "        plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prepared data"
      ],
      "metadata": {
        "id": "1qvMhpkA4L9u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szNksztu-5tv"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/MyDrive/data'\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "val_dir = os.path.join(data_dir, 'val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAke8oHl-5tx",
        "outputId": "4880e7e1-8c49-48c1-c748-e3dcebe38b3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Datasets and Dataloaders...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pretrained_size = 320\n",
        "\n",
        "pretrained_means = [0.485,0.456,0.406]\n",
        "\n",
        "pretrained_stds= [0.229,0.224,0.225]\n",
        "\n",
        "batch_size=8\n",
        "\n",
        "data_transforms = {\n",
        "\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((pretrained_size,pretrained_size)),\n",
        "                           transforms.RandomHorizontalFlip(),\n",
        "                           transforms.RandomRotation(10),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean = pretrained_means,\n",
        "                                                std = pretrained_stds)\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((pretrained_size,pretrained_size)),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean = pretrained_means,\n",
        "                                                std = pretrained_stds)\n",
        "    ]),\n",
        "                   }\n",
        "print(\"Initializing Datasets and Dataloaders...\\n\")\n",
        "# Create training and validation datasets\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "# Create training and validation dataloaders\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=2,pin_memory=True) for x in ['train', 'val']}\n",
        "device = torch.device(\"cuda:0\")\n",
        "dataset_sizes ={x:len(image_datasets[x]) for x in ['train','val']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CVhXuXi-5t1",
        "outputId": "a33d287b-cd69-48e8-942e-f152a2dccd61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>Class Names: ['fractured', 'non_fractured']\n",
            "\n",
            ">>Class Index: {'fractured': 0, 'non_fractured': 1}\n",
            "\n",
            ">>Number of images in training=4986\n",
            "\n",
            ">>Number of images in test=818\n",
            "\n",
            "    Number of steps for training set=624\n",
            "\n",
            "    Number of steps for test set=103\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Class names convert to index\n",
        "image_datasets['train'].class_to_idx\n",
        "class_names=image_datasets['train'].classes\n",
        "print(\">>Class Names: {}\\n\".format(image_datasets['train'].classes))\n",
        "print(\">>Class Index: {}\\n\".format(image_datasets['train'].class_to_idx))\n",
        "print(\">>Number of images in training={}\\n\".format(dataset_sizes['train']))\n",
        "print(\">>Number of images in test={}\\n\".format(dataset_sizes['val']))\n",
        "print(\"    Number of steps for training set={}\\n\".format(len(dataloaders['train'])))\n",
        "print(\"    Number of steps for test set={}\\n\".format(len(dataloaders['val'])))\n",
        "# 1:positive #0:negative"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#training function code"
      ],
      "metadata": {
        "id": "SpBK7Ovf4SQE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JHbsW8t-5t4"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_acc = []\n",
        "val_losses = []\n",
        "val_acc = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utooixmf-5t6"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    ghost=True\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    # if isinstance(outputs, tuple):\n",
        "                    #   outputs, aux = outputs\n",
        "                    # else:\n",
        "                    #     aux = None\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.detach() * inputs.size(0) #.item()\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss/ dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            #Losses and accuracy per epochs are stored in array for plot graphs\n",
        "            if phase == 'train':\n",
        "                train_losses.append(epoch_loss)\n",
        "                train_acc.append(epoch_acc)\n",
        "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "            if phase == 'val':\n",
        "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "                val_losses.append(epoch_loss)\n",
        "                val_acc.append(epoch_acc)\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "        torch.cuda.empty_cache()\n",
        "    # Determine total traning time\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    # Print best validation accuracy\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    torch.save(best_model_wts, \"./model.pth\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Models"
      ],
      "metadata": {
        "id": "kftwJmBD2oq4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##AlexNet"
      ],
      "metadata": {
        "id": "D0jdxxnu47_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft=models.alexnet(pretrained=True)\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_ft.parameters(), betas=(0.9,0.999), lr=0.0001)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "model_ft = train_model(model_ft, criterion, optimizer, exp_lr_scheduler,20)"
      ],
      "metadata": {
        "id": "SulBvkAa4gHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##VGG16, VGG19"
      ],
      "metadata": {
        "id": "YRtVjILn5wgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft =models.vgg19(pretrained=True)#models.vgg16,models.vgg19\n",
        "num_ftrs = model_ft.classifier[6].in_features\n",
        "model_ft.classifier[6] = nn.Sequential(nn.Linear(num_ftrs, 2))\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_ft.parameters(), betas=(0.9,0.999), lr=0.0001)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "model_ft = train_model(model_ft, criterion, optimizer, exp_lr_scheduler,20)"
      ],
      "metadata": {
        "id": "NSo4-A924_zQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##resnet18, resnet34, resnet50, resnet101, resnet152"
      ],
      "metadata": {
        "id": "dzl_tAqr6k0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft=models.resnet152(pretrained=True) #models.resnet18 models.resnet34,models.resnet50,models.resnet101,models.resnet152,\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc =nn.Sequential(nn.Linear(num_ftrs, 2),\n",
        "nn.Sigmoid())\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_ft.parameters(), betas=(0.9,0.999), lr=0.0001)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "model_ft = train_model(model_ft, criterion, optimizer, exp_lr_scheduler,20)"
      ],
      "metadata": {
        "id": "rTUopIpg50ZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##efficientnet-b0, efficientnet-b1, efficientnet-b7, efficientnet-V2"
      ],
      "metadata": {
        "id": "rmPQPYlL7W8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet_pytorch\n"
      ],
      "metadata": {
        "id": "_fnzRQNT6v2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from efficientnet_pytorch import EfficientNet"
      ],
      "metadata": {
        "id": "hBEAd7Dp7my9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet_model = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "num_ftrs = efficientnet_model._fc.in_features\n",
        "efficientnet_model._fc = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 2),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "model_ft = efficientnet_model\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_ft.parameters(), betas=(0.9,0.999), lr=0.0001)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "model_ft = train_model(model_ft, criterion, optimizer, exp_lr_scheduler,20)"
      ],
      "metadata": {
        "id": "kAPSrYzH7qdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dense169, Dense201"
      ],
      "metadata": {
        "id": "iH_pPJhi9mG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft =models.densenet169(pretrained=True)#models.densenet169,models.densenet201\n",
        "num_ftrs = model_ft.classifier.in_features\n",
        "model_ft.classifier = nn.Sequential(nn.Linear(num_ftrs, 2),\n",
        "nn.Sigmoid())\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_ft.parameters(), betas=(0.9,0.999), lr=0.0001)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "model_ft = train_model(model_ft, criterion, optimizer, exp_lr_scheduler,20)"
      ],
      "metadata": {
        "id": "0ufLmll89tQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MobileNetV2, MobileNetV3"
      ],
      "metadata": {
        "id": "_yjFSQcv-Z2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft=models.mobilenet_v3_small(pretrained=True)#models.mobilenet_v2, models.mobilenet_v3\n",
        "num_ftrs = model_ft.classifier[0].in_features\n",
        "model_ft.classifier =nn.Sequential(nn.Linear(num_ftrs, 2),\n",
        "nn.Sigmoid())\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_ft.parameters(), betas=(0.9,0.999), lr=0.0001)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "model_ft = train_model(model_ft, criterion, optimizer, exp_lr_scheduler,20)"
      ],
      "metadata": {
        "id": "or9dzzi4-iHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RegNet_y16"
      ],
      "metadata": {
        "id": "Q7jnIybk8ETs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = models.regnet_y_16gf(weights='IMAGENET1K_V1')\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc= nn.Sequential(nn.Linear(num_ftrs, 2))\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_ft.parameters(), betas=(0.9,0.999), lr=0.0001)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "model_ft = train_model(model_ft, criterion, optimizer, exp_lr_scheduler,20)"
      ],
      "metadata": {
        "id": "Xm1ofKcR75RN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iy8Sotih833H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RepVGG"
      ],
      "metadata": {
        "id": "ujdJ__tP2epH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/DingXiaoH/RepVGG.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUrhkv5yjmmu",
        "outputId": "90d6a957-1725-49dd-b9bb-72fc67d347fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RepVGG'...\n",
            "remote: Enumerating objects: 581, done.\u001b[K\n",
            "remote: Counting objects: 100% (236/236), done.\u001b[K\n",
            "remote: Compressing objects: 100% (97/97), done.\u001b[K\n",
            "remote: Total 581 (delta 191), reused 174 (delta 138), pack-reused 345\u001b[K\n",
            "Receiving objects: 100% (581/581), 485.19 KiB | 12.13 MiB/s, done.\n",
            "Resolving deltas: 100% (347/347), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from repvgg import create_RepVGG_A0"
      ],
      "metadata": {
        "id": "ivsIr81VoMhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from repvgg import create_RepVGG_A0  # Adjust the import path if necessary\n",
        "\n",
        "# Function to load the pretrained model with weights\n",
        "def load_pretrained_repvgg(model, weights_path):\n",
        "    checkpoint = torch.hub.load_state_dict_from_url(weights_path, map_location='cpu')\n",
        "    if 'state_dict' in checkpoint:\n",
        "        checkpoint = checkpoint['state_dict']\n",
        "    model.load_state_dict(checkpoint)\n",
        "    return model\n",
        "\n",
        "# Load the RepVGG model\n",
        "model_ft = create_RepVGG_A0(deploy=False)\n",
        "\n",
        "# Load the pretrained weights\n",
        "weights_url = 'https://github.com/DingXiaoH/RepVGG/releases/download/v1.0/RepVGG-A0-train.pth'\n",
        "model_ft = load_pretrained_repvgg(model_ft, weights_url)\n",
        "\n",
        "# Modify the classifier part\n",
        "num_ftrs = model_ft.head.in_features\n",
        "model_ft.head = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 2),\n",
        "    nn.Sigmoid()\n",
        ")"
      ],
      "metadata": {
        "id": "lH36AoGGoFT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8ut9Ukt-5uG"
      },
      "outputs": [],
      "source": [
        "#model_ft.load_state_dict(torch.load(\"./model.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeLEqZBO-5uH"
      },
      "outputs": [],
      "source": [
        "# Model send to GPU\n",
        "model_ft = model_ft.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moPjUO-f-5uH"
      },
      "outputs": [],
      "source": [
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.Adam(model_ft.parameters(), betas=(0.9,0.999), lr=0.0001)\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibPB3S4g-5uI",
        "outputId": "5745ffad-eb23-43ee-a3d6-75ac2e358def"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.4946 Acc: 0.8117\n",
            "val Loss: 0.4810 Acc: 0.8301\n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.4592 Acc: 0.8504\n",
            "val Loss: 0.4528 Acc: 0.8582\n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.4517 Acc: 0.8580\n",
            "val Loss: 0.4516 Acc: 0.8582\n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.4420 Acc: 0.8664\n",
            "val Loss: 0.4489 Acc: 0.8582\n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.4413 Acc: 0.8672\n",
            "val Loss: 0.4622 Acc: 0.8435\n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.4310 Acc: 0.8787\n",
            "val Loss: 0.4536 Acc: 0.8570\n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.4276 Acc: 0.8803\n",
            "val Loss: 0.4717 Acc: 0.8362\n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.4280 Acc: 0.8807\n",
            "val Loss: 0.4425 Acc: 0.8667\n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.4226 Acc: 0.8891\n",
            "val Loss: 0.4671 Acc: 0.8386\n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.4255 Acc: 0.8843\n",
            "val Loss: 0.4474 Acc: 0.8643\n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.4016 Acc: 0.9099\n",
            "val Loss: 0.4351 Acc: 0.8655\n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.3935 Acc: 0.9148\n",
            "val Loss: 0.4227 Acc: 0.8851\n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.3856 Acc: 0.9254\n",
            "val Loss: 0.4199 Acc: 0.8912\n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.3880 Acc: 0.9220\n",
            "val Loss: 0.4192 Acc: 0.8863\n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.3811 Acc: 0.9316\n",
            "val Loss: 0.4223 Acc: 0.8839\n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.3796 Acc: 0.9320\n",
            "val Loss: 0.4172 Acc: 0.8961\n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.3734 Acc: 0.9372\n",
            "val Loss: 0.4189 Acc: 0.8863\n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.3690 Acc: 0.9462\n",
            "val Loss: 0.4087 Acc: 0.8985\n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.3702 Acc: 0.9426\n",
            "val Loss: 0.4061 Acc: 0.9010\n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.3703 Acc: 0.9410\n",
            "val Loss: 0.4116 Acc: 0.8936\n",
            "\n",
            "Training complete in 112m 25s\n",
            "Best val Acc: 0.900978\n"
          ]
        }
      ],
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer, exp_lr_scheduler,20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYv2TCMW-5uO"
      },
      "source": [
        " #  Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8GOMJ7X-5uP",
        "outputId": "57dfd62c-4720-4e31-e467-bdd459b6e497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct Prediction: 737  Total Images: 818\n",
            "Test Accuracy = 0.900978\n"
          ]
        }
      ],
      "source": [
        "get_metric.test_model(model_ft,device,dataloaders['val'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0t7Gn0PP-5uQ"
      },
      "outputs": [],
      "source": [
        "actuals, predictions = get_metric.test_label_predictions(model_ft, device, dataloaders['val'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leJBWhkC-5uS",
        "outputId": "f71eb02a-c1a4-4559-a432-d097ed2125cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.65      0.70       144\n",
            "           1       0.93      0.96      0.94       674\n",
            "\n",
            "    accuracy                           0.90       818\n",
            "   macro avg       0.84      0.80      0.82       818\n",
            "weighted avg       0.90      0.90      0.90       818\n",
            "\n"
          ]
        }
      ],
      "source": [
        "get_metric.get_classification_report(actuals, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "Vlow-4Wn-5uS",
        "outputId": "f0ace9a7-9f9e-4e0c-dc66-e4d7337f5af8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            " [[ 93  51]\n",
            " [ 30 644]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "get_metric.get_confusion_matrix(actuals, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okpjlqhn-5uT",
        "outputId": "1dc4db56-fb36-459d-a223-f1bb02ebee02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kappa Score of this model:\n",
            " 0.6378988097189887\n"
          ]
        }
      ],
      "source": [
        "get_metric.get_cohen_kappa(actuals, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKPK2kEt-5uU"
      },
      "outputs": [],
      "source": [
        "get_metric.get_roc_curves(model_ft, device,  dataloaders['val'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}